{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Objective: ETL Out-Station Performance data\n",
    "\n",
    "Input: Excel file containing \n",
    "    1. flight_date,\n",
    "    2. flight_status, \n",
    "    3. flight_no, \n",
    "    4. sector, \n",
    "    5. aircraft, \n",
    "    6. capacity_business, \n",
    "    7. capacity_p_economy, \n",
    "    8. capacity_economy,\n",
    "    9. travelled_business, \n",
    "    10. travelled_p_economy, \n",
    "    11. travelled_economy, \n",
    "    12. cargo_quantity, \n",
    "    13. ex_baggage_quantity, \n",
    "    14. ex_baggage_revenue_local,\n",
    "    15. ex_baggage_revenue_bd, \n",
    "    16. ex_baggage_revenue_local_currency,\n",
    "    17. otp_quantity, \n",
    "    18. otp_status, \n",
    "    19. otp_remarks,\n",
    "    20. pax_load_factor_business, \n",
    "    21. pax_load_factor_p_economy,\n",
    "    22. pax_load_factor_economy,\n",
    "    23. pax_load_factor_total, \n",
    "    24. remarks\n",
    "    \n",
    "Output: Storage of KPIs Pax-Ratio, OTP, Excess-Baggage Revenue and Cargo Revenue\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "uploadedFolder = r\"raw_data_location\"\n",
    "insertedFolder = r\"processed_data_location\"\n",
    "\n",
    "for file in os.listdir(uploadedFolder):\n",
    "    if file.endswith('.xlsx'):\n",
    "        file_path = uploadedFolder +\"\\\\\"+ file\n",
    "       \n",
    "        read_df     = read_excel_file(file_path)\n",
    "        clean_df    = clean_data(read_df)\n",
    "        custom_df   = customize_data(clean_df)\n",
    "        loadedFile  = insert_data(custom_df)\n",
    "        relocate_file(file, file_path, custom_df, insertedFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "target_string_column = \"DATE\"\n",
    "target_string_row = \"TOTAL\"\n",
    "\n",
    "def read_excel_file(file):\n",
    "    global df\n",
    "    print(\"---------Reading starting----------\")\n",
    "    xls = pd.ExcelFile(file)\n",
    "    \n",
    "    # Iterate over sheet names\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name, header=None , keep_default_na=False)\n",
    "    \n",
    "        # Find the rows where the target string is located in the first column\n",
    "        column_match =  np.argwhere(np.char.startswith(df.values.astype(str), target_string_column))\n",
    "        row_match = df[df.iloc[:, 0].astype(str).str.contains(target_string_row)]\n",
    "    \n",
    "        if not column_match.size == 0:\n",
    "            df_filtered = df.iloc[2:row_match.index[0], column_match[0][1]:]\n",
    "            print(f\"Reading up to '{target_string_column}' in sheet '{sheet_name}':\")\n",
    "        else:\n",
    "            print(f\"'{target_string_column}' not found in sheet '{sheet_name}'\")\n",
    "            \n",
    "    xls.close()  # Close the Excel file\n",
    "\n",
    "    print(\"---------Reading ended----------\")\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "na_values = ['N/A']\n",
    "\n",
    "def clean_data(read_df):\n",
    "    print(\"---------Cleaning starting----------\")\n",
    "    \n",
    "    d3= read_df.convert_dtypes()\n",
    "    d3.replace('', np.nan, inplace=True)\n",
    "    \n",
    "    # Identify the columns intended to be float\n",
    "    float_columns = [11, 12, 13, 14, 19, 20, 21, 22]\n",
    "    d3[float_columns] = d3[float_columns].astype(float)\n",
    "\n",
    "    # Identify the columns intended to be integers\n",
    "    int_columns = [16]\n",
    "    \n",
    "    # Convert columns to integers and handle NaN or infinite values\n",
    "    d3[int_columns] = d3[int_columns].apply(lambda x: pd.to_numeric(x, errors='coerce')).astype('Int64')\n",
    "\n",
    "    # df_datatype_corrected = d3.astype({ 11: float, 12: float, 13:float, 14:float, 16: int, 19:float, 20:float, 21:float, 22:float})\n",
    "    df_datatype_corrected = d3\n",
    "    non_numeric_columns = df_datatype_corrected.select_dtypes(exclude='number').columns\n",
    "    df_datatype_corrected[non_numeric_columns] = df_datatype_corrected[non_numeric_columns].fillna('N/A')\n",
    "    \n",
    "    df_nullRowFiltered = df_datatype_corrected.dropna(how='all')\n",
    "    df_nullCellTransformed = df_nullRowFiltered.fillna(0)\n",
    "    df_allCellTrimmed = trim_all_columns(df_nullCellTransformed)\n",
    "    \n",
    "    print(\"---------Cleaning ended----------\")\n",
    "    return df_allCellTrimmed\n",
    "\n",
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "currency_rate = {\n",
    "    'GBP':\t111,\n",
    "    'AOA':\t111,\n",
    "    'AUD':\t111,\n",
    "    'BHD':\t111,\n",
    "    'EUR':\t111,\n",
    "    'BGN':\t111,\n",
    "    'CAD':\t111,\n",
    "    'XAF':\t111,\n",
    "    'CNY':\t111,\n",
    "    'TWD':\t111,\n",
    "    'CZK':\t111,\n",
    "    'ETB':\t111\n",
    "    }\n",
    "\n",
    "def customize_data(cleanedFile):\n",
    "    print(\"---------Customization started----------\")\n",
    "   \n",
    "    df_headers = ['flight_date','flight_status', 'flight_no', 'sector', 'aircraft', \n",
    "                    'capacity_business', 'capacity_p_economy', 'capacity_economy' ,\n",
    "                    'travelled_business', 'travelled_p_economy', 'travelled_economy', \n",
    "                    'cargo_quantity', 'ex_baggage_quantity', 'ex_baggage_revenue_local','ex_baggage_revenue_bd', 'ex_baggage_revenue_local_currency',\n",
    "                    'otp_quantity', 'otp_status', 'otp_remarks',\n",
    "                    'pax_load_factor_business', 'pax_load_factor_p_economy','pax_load_factor_economy','pax_load_factor_total', 'remarks'\n",
    "                ]\n",
    "   \n",
    "    cleanedFile.columns = df_headers\n",
    "    '''\n",
    "    The `ex_baggage_revenue_bd` column is being calculated based on the `ex_baggage_revenue_local` and `ex_baggage_revenue_local_currency` columns in the DataFrame. \n",
    "    The calculation involves converting the revenue from the local currency to Bangladeshi Taka (BDT) using the currency exchange rates provided in the `currency_rate` dictionary. \n",
    "    The conversion is done by multiplying the revenue in the local currency by the corresponding exchange rate for that currency. \n",
    "    The result is then rounded to the nearest whole number using the `ROUND_HALF_UP` method from the `decimal` module with precision set to 3 decimal places. \n",
    "    If the currency is not found in the `currency_rate` dictionary, the value in the `ex_baggage_revenue_bd` column is set to 0.\n",
    "    '''\n",
    "    cleanedFile[' ex_baggage_revenue_bd'] = cleanedFile.apply(lambda row: Decimal(row['ex_baggage_revenue_local'] * currency_rate[row['ex_baggage_revenue_local_currency']]).quantize(Decimal('0.000'), rounding=ROUND_HALF_UP) if row['ex_baggage_revenue_local_currency'] in currency_rate else 0, axis=1)\n",
    "\n",
    "    cleanedFile['pax_load_factor_business']     = cleanedFile.apply(lambda x: calculate_load_factor(x,1), axis=1)\n",
    "    cleanedFile['pax_load_factor_p_economy']    = cleanedFile.apply(lambda x: calculate_load_factor(x,2), axis=1)\n",
    "    cleanedFile['pax_load_factor_economy']      = cleanedFile.apply(lambda x: calculate_load_factor(x,3), axis=1)\n",
    "    cleanedFile['pax_load_factor_total']        = cleanedFile.apply(lambda x: calculate_load_factor(x,4), axis=1) \n",
    "    cleanedFile['flight_date']                  = cleanedFile['flight_date'].apply(lambda x: transform_date(x))\n",
    "     \n",
    "    print(\"---------Customization ended----------\")\n",
    "    \n",
    "    return cleanedFile\n",
    "\n",
    "def transform_date(input_date):\n",
    "    formats = ['%d/%m/%Y','%d-%m-%Y','%d.%m.%Y','%d.%m.%y', '%m/%d/%Y', \"%b'%y\",\"%d %b.'%y\",'%y/%m/%d', '%Y-%m-%d %H:%M:%S', \"%d %b'%y\"]\n",
    "\n",
    "    # Check if the input_date is a Pandas Timestamp\n",
    "    if isinstance(input_date, pd.Timestamp):\n",
    "        date_obj = input_date.to_pydatetime()\n",
    "        return date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Convert the input_date to a string if it's not already\n",
    "    input_date_str = str(input_date)\n",
    "\n",
    "    for date_format in formats:\n",
    "        try:\n",
    "            date_obj = datetime.strptime(input_date_str, date_format)\n",
    "            return date_obj.strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    raise ValueError('Invalid date format: {}'.format(input_date_str))\n",
    "\n",
    "def calculate_load_factor(row, indicator):\n",
    "    try:\n",
    "        if indicator == 4:\n",
    "            numerator = int(row['travelled_business']) + int(row['travelled_p_economy']) + int(row['travelled_economy'])\n",
    "            denominator = int(row['capacity_business']) + int(row['capacity_p_economy']) + int(row['capacity_economy'])\n",
    "        elif indicator == 3:\n",
    "            numerator = int(row['travelled_economy'])\n",
    "            denominator = int(row['capacity_economy'])\n",
    "        elif indicator == 2:\n",
    "            numerator = int(row['travelled_p_economy'])\n",
    "            denominator = int(row['capacity_p_economy'])\n",
    "        elif indicator == 1:\n",
    "            numerator = int(row['travelled_business'])\n",
    "            denominator = int(row['capacity_business'])\n",
    "            \n",
    "        if denominator == 0:\n",
    "            # Handle division by zero\n",
    "            return 0\n",
    "        else:\n",
    "            return (numerator * 100) / denominator\n",
    "    except ZeroDivisionError:\n",
    "        # Handle division by zero\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        # Handle other exceptions if necessary\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def insert_data (df_data_final):\n",
    "    \n",
    "    print(\"---------Loading starting----------\")\n",
    "    mydb = pymysql.connect(\n",
    "        host        = \"host_name\",\n",
    "        user        = \"user_name\",\n",
    "        database    = \"db_name\",\n",
    "        password    = \"password\")\n",
    "\n",
    "    engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                           .format(user =\"user_name\",\n",
    "                                   host =\"host_name\",\n",
    "                                   pw   =\"password\",\n",
    "                                   db   =\"db_name\"))\n",
    "    df_data_reset = df_data_final.reset_index(drop=True)\n",
    "    \n",
    "    # Define a mapping from Pandas data types to SQL data types\n",
    "    pandas_to_sql_type_mapping = {\n",
    "        'int32'         : 'INT',\n",
    "        'int64'         : 'INT',\n",
    "        'float64'       : 'FLOAT',\n",
    "        'object'        : 'TEXT',  # This includes strings\n",
    "        'datetime64[ns]': 'TIMESTAMP',\n",
    "    }\n",
    "    \n",
    "    SQL_CREATE_TBL = \"CREATE TABLE IF NOT EXISTS table_name(id INT NOT NULL AUTO_INCREMENT,\"\n",
    "    \n",
    "    for column_name, data_type in zip(df_data_reset.columns, df_data_reset.dtypes):\n",
    "        # Map Pandas data types to SQL data types\n",
    "        sql_data_type = pandas_to_sql_type_mapping.get(str(data_type), 'TEXT')\n",
    "    \n",
    "        # Add column definition to the SQL statement\n",
    "        SQL_CREATE_TBL += \"{} {}, \".format(column_name, sql_data_type)\n",
    "    SQL_CREATE_TBL += \"created_at TIMESTAMP NOT NULL DEFAULT current_timestamp(), updated_at TIMESTAMP NOT NULL DEFAULT current_timestamp(), PRIMARY KEY (id));\"\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(\"table_name\"), end='')\n",
    "        mycursor.execute(SQL_CREATE_TBL)\n",
    "        df_data_reset.to_sql('table_name', con= engine, if_exists= 'append', chunksize=1000, index=False)\n",
    "    except pymysql.Error as err:\n",
    "        print(err)\n",
    "        pass\n",
    "    else:\n",
    "        print(\"OK\")\n",
    "        \n",
    "    print(\"---------Loading ended----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processed Data File Relocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pathlib\n",
    "\n",
    "def relocate_file(file, file_path, customizedFile, insertedFolder):\n",
    "    print(\"---------Renaming and Relocating starting----------\")\n",
    "    \n",
    "    timestr = time.strftime(\"%d%m%Y_%H%M%S_\")\n",
    "    \n",
    "    transformedDataFile =  timestr + customizedFile.iloc[0].sector[:3] + \"_\"+customizedFile['flight_date'].iloc[0]+\"_\"+customizedFile['flight_date'].iloc[-1]+\".xlsx\"\n",
    "    uploaded_file_path = insertedFolder + \"\\\\\" + transformedDataFile\n",
    "    customizedFile.to_excel(uploaded_file_path, index= False)\n",
    "    \n",
    "    backup_file_path = insertedFolder + \"\\\\\" + timestr + file\n",
    "    newName = pathlib.PurePosixPath(backup_file_path).stem + '.xlsx'\n",
    "    \n",
    "    # os.rename(transfomedData, transformedDataFile)\n",
    "    os.rename(file_path, newName)\n",
    "    print(\"---------Renaming and Relocating ended----------\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
